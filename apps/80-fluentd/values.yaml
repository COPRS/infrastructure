image:
  repository: bitnami/fluentd
  tag: 1.14.2-debian-10-r23

config:
  auth_enabled: false
metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 2m
forwarder:
  enabled: false
aggregator:
  persistence:
    enabled: true
    storageClass: ceph-block
    size: 10Gi
  replicaCount: 2
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
            - key: "node-role.kubernetes.io/infra"
              operator: Exists
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 256Mi
  extraArgs: "-v -p /etc/fluent/custom_plugins/"
  extraVolumes:
    - name: fluentd-custom-plugins
      configMap:
        name: fluentd-custom-plugins
    - name: elasticsearch-templates
      configMap:
        name: elasticsearch-templates
  extraVolumeMounts:
    - name: fluentd-custom-plugins
      mountPath: /etc/fluent/custom_plugins/
    - name: elasticsearch-templates
      mountPath: /etc/fluent/elasticsearch_templates
  configMapFiles:
    {% raw %}
    fluentd.conf: |
      # Ignore fluentd own events
      <label @FLUENT_LOG>
        <match **>
          @type null
          @id ignore_fluent_logs
        </match>
      </label>
      @include fluentd-inputs.conf
      @include fluentd-output.conf
      {{- if .Values.metrics.enabled }}
      @include metrics.conf
      {{- end }}
    {% endraw %}
    fluentd-inputs.conf: |
      <source>
        @type kafka_group
        brokers kafka-cluster-kafka-bootstrap.infra.svc.cluster.local:9092
        consumer_group fluentd
        topics fluentbit.system,fluentbit.processing,fluentbit.trace
      </source>
      # Readyness probes source
      <source>
        @type http
        bind 0.0.0.0
        port 9880
      </source>
    fluentd-output.conf: |
      <filter fluentbit.system>
        @type parser
        key_name log
        <parse>
          @type regexp
          expression /^(?<time>[^ ]*\s+[^ ]*\s+[^ ]*)\s+(?<hostname>[^ ]*)\s+(?<processus>[^ ]*)\:\s+(?<log>.*)$/
          time_format %b %d %H:%M:%S 
        </parse>
      </filter>

      <filter fluentbit.processing fluentbit.system fluentbit.trace>
        @type icd_formatter
      </filter>
      
      <filter fluentbit.trace fluentbit.processing fluentbit.system>
        @type record_transformer
        remove_keys @timestamp, time
      </filter>
       <filter fluentbit.trace>
         @type filename_properties
         key log
       </filter>

      <filter **>
        @type rename_key
        replace_rule1 \. _
      </filter>

      <filter fluentbit.processing fluentbit.system>
        @type record_transformer
        <record>
          fluentd_worker "#{hostname}-#{worker_id}"
        </record>
      </filter>

      <match fluentbit.processing>
        @type loki
        url "http://loki.monitoring.svc.cluster.local:3100"
        extra_labels {"loki":"processing"}
        <label>
          fluentd_worker
        </label>
        flush_interval 10s
        flush_at_shutdown true
        buffer_chunk_limit 1m
        extract_kubernetes_labels true
        remove_keys kubernetes
      </match>

      <match fluentbit.system>
        @type loki
        url "http://loki.monitoring.svc.cluster.local:3100"
        extra_labels {"loki":"system"}
        <label>
          fluentd_worker
        </label>
        flush_interval 10s
        flush_at_shutdown true
        buffer_chunk_limit 1m
      </match>

      <match fluentbit.trace>
        @id elasticsearch_index_trace
        @type elasticsearch
        @log_level info
        type_name _doc
        host elasticsearch-processing-es-coordinating.database.svc.cluster.local
        port 9200
        scheme http
        ssl_verify false
        logstash_format true
        logstash_prefix processing_trace
        suppress_type_name true
        reconnect_on_error true
        log_es_400_reason true
        time_key_format %Y-%m-%dT%H:%M:%S.%NZ
        templates {"static_trace": "/etc/fluent/elasticsearch_templates/static_trace.json", "dynamic_trace": "/etc/fluent/elasticsearch_templates/dynamic_trace.json"}
        template_overwrite true
        <buffer>
          @type file
          path /opt/bitnami/fluentd/logs/buffers/fluentd.elastic.buffer.trace
          flush_mode interval
          retry_type exponential_backoff
          flush_thread_count 2
          flush_interval 5s
          retry_forever
          retry_max_interval 30
          chunk_limit_size 2M
          queue_limit_length 8
          overflow_action block
        </buffer>
      </match>
