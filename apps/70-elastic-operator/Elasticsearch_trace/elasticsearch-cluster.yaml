apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: elasticsearch-trace
spec:
  auth:
    fileRealm:
      - secretName: elasticsearch-trace-filerealm-secret
  http:
    tls:
      selfSignedCertificate:
        disabled: true
  version: 7.15.2
  nodeSets:
    - name: master-nodes
      count: 1
      config:
        xpack.security.authc.anonymous:
          username: anonymous
          roles: superuser
          authz_exception: false
        node.roles: ["master"]
        s3.client.default.endpoint: {{ eck_backup_bucket.endpoint }}
        s3.client.default.region: {{ eck_backup_bucket.region }}
      volumeClaimTemplates:
        - metadata:
            name: elasticsearch-data # Do not change this name unless you set up a volume mount for the data path.
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 10Gi
            storageClassName: ceph-block
      podTemplate:
        metadata:
          annotations:
            config.linkerd.io/skip-outbound-ports: "443"
            config.linkerd.io/opaque-ports: "9300"
        spec:
          automountServiceAccountToken: true
          initContainers:
            - name: install-plugin
              envFrom:
                - secretRef:
                    name: eck-s3-credentials
              command:
                - sh
                - -c
                - |
                  bin/elasticsearch-plugin install --batch repository-s3
                  echo $S3_ACCESS_KEY | bin/elasticsearch-keystore add --stdin --force s3.client.default.access_key
                  echo $S3_SECRET_KEY | bin/elasticsearch-keystore add --stdin --force s3.client.default.secret_key
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                    - key: "node-role.kubernetes.io/infra"
                      operator: Exists
          containers:
            - name: elasticsearch
              resources:
                limits:
                  cpu: 1500m
                  memory: 6Gi
                requests:
                  cpu: 500m
                  memory: 2Gi
              readinessProbe:
                exec:
                  command:
                  - bash
                  - -c
                  - /mnt/elastic-internal/scripts/readiness-probe-script.sh
                failureThreshold: 3
                initialDelaySeconds: 60
                periodSeconds: 22
                successThreshold: 1
                timeoutSeconds: 22
              env:
              - name: READINESS_PROBE_TIMEOUT
                value: "20"
    - name: data-nodes
      count: 2
      config:
        xpack.security.authc.anonymous:
          username: anonymous
          roles: superuser
          authz_exception: false
        node.roles: ["data"]
        s3.client.default.endpoint: {{ eck_backup_bucket.endpoint }}
        s3.client.default.region: {{ eck_backup_bucket.region }}
      volumeClaimTemplates:
        - metadata:
            name: elasticsearch-data # Do not change this name unless you set up a volume mount for the data path.
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 80Gi
            storageClassName: ceph-block
      podTemplate:
        metadata:
          annotations:
            config.linkerd.io/skip-outbound-ports: "443"
            config.linkerd.io/opaque-ports: "9300"
        spec:
          automountServiceAccountToken: true
          initContainers:
            - name: install-plugin
              envFrom:
                - secretRef:
                    name: eck-s3-credentials
              command:
                - sh
                - -c
                - |
                  bin/elasticsearch-plugin install --batch repository-s3
                  echo $S3_ACCESS_KEY | bin/elasticsearch-keystore add --stdin --force s3.client.default.access_key
                  echo $S3_SECRET_KEY | bin/elasticsearch-keystore add --stdin --force s3.client.default.secret_key
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                    - key: "node-role.kubernetes.io/infra"
                      operator: Exists
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchExpressions:
                      - key: elasticsearch.k8s.elastic.co/cluster-name
                        operator: In
                        values:
                          - 'elasticsearch-cluster'
                  topologyKey: kubernetes.io/hostname
          containers:
            - name: elasticsearch
              resources:
                limits:
                  cpu: 1500m
                  memory: 6Gi
                requests:
                  cpu: 500m
                  memory: 2Gi
