image:
  repository: bitnami/fluentd
  tag: 1.14.2-debian-10-r23

config:
  auth_enabled: false
metrics:
  enabled: true
forwarder:
  enabled: false
aggregator:
  persistence:
    enabled: true
    storageClass: ceph-block
    size: 10Gi
  replicaCount: 2
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
            - key: "node-role.kubernetes.io/infra"
              operator: Exists
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 256Mi
  extraArgs: "-v -p /etc/fluent/custom_plugins/"
  extraVolumes:
    - name: fluentd-custom-plugins
      configMap:
        name: fluentd-custom-plugins
    - name: elasticsearch-templates
      configMap:
        name: elasticsearch-templates
  extraVolumeMounts:
    - name: fluentd-custom-plugins
      mountPath: /etc/fluent/custom_plugins/
    - name: elasticsearch-templates
      mountPath: /etc/fluent/elasticsearch_templates
  configMapFiles:
    fluentd.conf: |
      # Ignore fluentd own events
      <label @FLUENT_LOG>
        <match **>
          @type null
          @id ignore_fluent_logs
        </match>
      </label>
      @include fluentd-inputs.conf
      @include fluentd-output.conf
      @include metrics.conf
    fluentd-inputs.conf: |
      <source>
        @type kafka_group
        brokers kafka-cluster-kafka-bootstrap.infra.svc.cluster.local:9092
        consumer_group fluentd
        topics fluentbit.trace
      </source>
      <source>
        @type kafka_group
        brokers kafka-cluster-kafka-bootstrap.infra.svc.cluster.local:9092
        consumer_group fluentd
        topics /.*(event|job)/
      </source>
      # Readyness probes source
      <source>
        @type http
        bind 0.0.0.0
        port 9880
      </source>
    fluentd-output.conf: |
      <filter fluentbit.trace>
        @type icd_formatter
      </filter>
      
      <filter fluentbit.trace>
        @type record_transformer
        remove_keys @timestamp, time
      </filter>

      <filter fluentbit.trace>
        @type filename_properties
        key log
      </filter>

      <filter **>
        @type rename_key
        replace_rule1 \. _
      </filter>

      <filter {**event,**job}>
        @type record_transformer
        <record>
          kafka_topic ${tag}
        </record>
      </filter>

      <match {**event,**job}>
        @type loki
        url "http://loki-loki-distributed-distributor.logging.svc.cluster.local:3100"
        <label>
          kafka_topic
        </label>
        flush_interval 10s
        flush_at_shutdown true
        buffer_chunk_limit 2m
        #extract_kubernetes_labels true
        #remove_keys kubernetes
      </match>

      <match fluentbit.trace>
        @id elasticsearch_index_trace
        @type elasticsearch
        @log_level info
        type_name _doc
        host elasticsearch-processing-es-coordinating.database.svc.cluster.local
        port 9200
        scheme http
        ssl_verify false
        logstash_format true
        logstash_prefix processing_trace
        suppress_type_name true
        reconnect_on_error true
        log_es_400_reason true
        time_key_format %Y-%m-%dT%H:%M:%S.%NZ
        templates {"static_trace": "/etc/fluent/elasticsearch_templates/static_trace.json", "dynamic_trace": "/etc/fluent/elasticsearch_templates/dynamic_trace.json"}
        template_overwrite true
        <buffer>
          @type file
          path /opt/bitnami/fluentd/logs/buffers/fluentd.elastic.buffer.trace
          flush_mode interval
          retry_type exponential_backoff
          flush_thread_count 2
          flush_interval 5s
          retry_forever
          retry_max_interval 30
          chunk_limit_size 2m
          queue_limit_length 8
          overflow_action block
        </buffer>
      </match>
