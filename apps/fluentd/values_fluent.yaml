kind: "StatefulSet"

replicaCount: 1

image:
  repository: "fluent/fluentd"
  tag: "v1.14.2-1.0"

## Additional environment variables to set for fluentd pods
env:
- name: "FLUENTD_CONF"
  value: "../../etc/fluent/fluent.conf"
  # - name: FLUENT_ELASTICSEARCH_HOST
  #   value: "elasticsearch-master"
  # - name: FLUENT_ELASTICSEARCH_PORT
  #   value: "9200"

volumes:
- name: varlog
  hostPath:
    path: /var/log
- name: varlibdockercontainers
  hostPath:
    path: /var/lib/docker/containers
- name: etcfluentd-main
  configMap:
    name: fluentd-main
    defaultMode: 0777
- name: etcfluentd-config
  configMap:
    name: fluentd-config
    defaultMode: 0777
- name: custom-plugins
  configMap:
    name: fluentd-custom-plugins

volumeMounts:
- name: varlog
  mountPath: /var/log
- name: varlibdockercontainers
  mountPath: /var/lib/docker/containers
  readOnly: true
- name: etcfluentd-main
  mountPath: /etc/fluent
- name: etcfluentd-config
  mountPath: /etc/fluent/config.d/
- name: custom-plugins
  mountPath: /etc/fluent/plugin/custom/

persistence:
  enabled: true
  storageClass: ceph-block
  accessMode: ReadWriteOnce
  size: 10Gi

dashboards:
  enabled: false
  namespace: monitoring
  labels:
    grafana_dashboard: '"1"'

plugins:
  - fluent-plugin-grafana-loki
  - rename_key

configMapConfigs: []

## Fluentd configurations:
##
fileConfigs:
  01_sources.conf: |-
    <source>
      @type kafka_group
      brokers kafka.infra.svc.cluster.local:9092
      consumer_group fluentd
      topics fluentbit.system,fluentbit.processing,fluentbit.trace
      <storage>
        @type local
        path /var/log/fluentd-buffers/kafka.fld
        pretty_print true
      </storage>
    </source>

  02_filters.conf: |-
    <filter fluentbit.system>
      @type parser
      key_name log
      <parse>
        @type regexp
        expression /^(?<time>[^ ]*\s+[^ ]*\s+[^ ]*)\s+(?<hostname>[^ ]*)\s+(?<processus>[^ ]*)\:\s+(?<log>.*)$/
        time_format %b %d %H:%M:%S 
      </parse>
    </filter>

    <filter fluentbit.processing fluentbit.system fluentbit.trace>
      @type icd_formatter
    </filter>
    
    <filter fluentbit.trace fluentbit.processing fluentbit.system>
      @type record_transformer
      remove_keys @timestamp, time
    </filter>
    <filter fluentbit.trace>
      @type filename_properties
      key log
    </filter>

    <filter **>
      @type rename_key
      replace_rule1 \. _
    </filter>

    <filter fluentbit.processing fluentbit.system>
      @type record_transformer
      <record>
        fluentd_worker "#{hostname}-#{worker_id}"
      </record>
    </filter>

  04_outputs.conf: |-
    <match fluentbit.processing>
      @type copy
      <store>
        @type loki
        url "http://loki.monitoring.svc.cluster.local:3100"
        extra_labels {"loki":"processing"}
        <label>
          fluentd_worker
        </label>
        flush_interval 10s
        flush_at_shutdown true
        buffer_chunk_limit 1m
        extract_kubernetes_labels true
        remove_keys kubernetes
      </store>
    </match>

    <match fluentbit.system>
      @type copy
      <store>
        @type loki
        url "http://loki.monitoring.svc.cluster.local:3100"
        extra_labels {"loki":"system"}
        <label>
          fluentd_worker
        </label>
        flush_interval 10s
        flush_at_shutdown true
        buffer_chunk_limit 1m
      </store>
    </match>

    <match fluentbit.trace>
      @id elasticsearch_index_trace
      @type elasticsearch
      @log_level info
      type_name _doc
      host elasticsearch.infra.svc.cluster.local
      port 9200
      scheme http
      ssl_version TLSv1
      ssl_verify true
      logstash_format true
      logstash_prefix processing_trace
      suppress_type_name true
      reconnect_on_error true
      log_es_400_reason true
      time_key_format %Y-%m-%dT%H:%M:%S.%NZ
      <buffer>
        @type file
        path /var/log/fluentd-buffers/fluentd.elastic.buffer.trace
        flush_mode interval
        retry_type exponential_backoff
        flush_thread_count 2
        flush_interval 5s
        retry_forever
        retry_max_interval 30
        chunk_limit_size 2M
        queue_limit_length 8
        overflow_action block
      </buffer>
    </match>